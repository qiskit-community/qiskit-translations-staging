


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="fr-FR" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="fr-FR" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Effective Dimension of Qiskit Neural Networks &mdash; Documentation Qiskit Machine Learning 0.4.0</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/jupyter-sphinx.css" type="text/css" />
  <link rel="stylesheet" href="../_static/thebelab.css" type="text/css" />
  <link rel="stylesheet" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/style.css" type="text/css" />
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Rechercher" href="../search.html" />
    <link rel="next" title="Qiskit Machine Learning API Reference" href="../apidocs/qiskit_machine_learning.html" />
    <link rel="prev" title="Saving, Loading Qiskit Machine Learning Models and Continuous Training" href="09_saving_and_loading%20models.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://qiskit.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="../getting_started.html">Getting started</a>
          </li>

          <li>
            <a href="https://qiskit.org/documentation/machine-learning/tutorials/index.html" target="_blank">Tutorials</a>
          </li>

          <li>
            <a href="https://qiskit.org/documentation/partners/" target="_blank">Partners</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Applications
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://qiskit.org/documentation/machine-learning/">
                  <span class="dropdown-title">Machine learning</span>
                  <p>QSVM, VQC (Variational Quantum Classifier), and QGAN (Quantum Generative
                    Adversarial Network) algorithms.</p>
                </a>
                <a class="nav-dropdown-item" href="https://qiskit.org/documentation/nature/">
                  <span class="dropdown-title">Nature</span>
                  <p>Quantum applications in chemistry, physics, and biology.</p>
                </a>
                <a class="nav-dropdown-item" href="https://qiskit.org/documentation/finance/">
                  <span class="dropdown-title">Finance</span>
                  <p>Uncertainty components for stock/securities problems, Ising translators for
                    portfolio optimizations and data providers to source real or random data.</p>
                </a>
                <a class="nav-dropdown-item" href="https://qiskit.org/documentation/optimization/">
                  <span class="dropdown-title">Optimization</span>
                  <p>High-level optimization problems that are ready to
                    run on simulators and real quantum devices</p>
                </a>
              </div>
          </li>
          <li>
              <a href="https://qiskit.org/documentation/experiments/" target="_blank">Experiments</a>
          </li>
          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://qiskit.slack.com">
                  <span class="dropdown-title">Slack support</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://qiskit.org/textbook">
                  <span class="dropdown-title">Qiskit Textbook</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://qiskit.org/events">
                  <span class="dropdown-title">Qiskit events</span>
                  <p></p>
                </a>
            </div>
          </li>
          <li>
            <a href="https://github.com/Qiskit/qiskit-machine-learning" target="_blank">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="rst-current-version-label">French</span>
    <span class="rst-versions-dropdown-icon"></span>
  </span>
  <div class="rst-other-versions">
    
    <dl>
      <dt>Langues</dt>
      
        <dd><a class="version" href="/documentation/machine-learning/tutorials/10_effective_dimension.html">English</a></dd>
      
        <dd><a class="version" href="/documentation/machine-learning/locale/bn_BN/tutorials/10_effective_dimension.html">Bengali</a></dd>
      
        <dd><a class="version" href="/documentation/machine-learning/locale/fr_FR/tutorials/10_effective_dimension.html">French</a></dd>
      
        <dd><a class="version" href="/documentation/machine-learning/locale/hi_IN/tutorials/10_effective_dimension.html">Hindi</a></dd>
      
        <dd><a class="version" href="/documentation/machine-learning/locale/it_IT/tutorials/10_effective_dimension.html">Italian</a></dd>
      
        <dd><a class="version" href="/documentation/machine-learning/locale/ja_JP/tutorials/10_effective_dimension.html">Japanese</a></dd>
      
        <dd><a class="version" href="/documentation/machine-learning/locale/ko_KR/tutorials/10_effective_dimension.html">Korean</a></dd>
      
        <dd><a class="version" href="/documentation/machine-learning/locale/ml_IN/tutorials/10_effective_dimension.html">Malayalam</a></dd>
      
        <dd><a class="version" href="/documentation/machine-learning/locale/ru_RU/tutorials/10_effective_dimension.html">Russian</a></dd>
      
        <dd><a class="version" href="/documentation/machine-learning/locale/es_UN/tutorials/10_effective_dimension.html">Spanish</a></dd>
      
        <dd><a class="version" href="/documentation/machine-learning/locale/ta_IN/tutorials/10_effective_dimension.html">Tamil</a></dd>
      
        <dd><a class="version" href="/documentation/machine-learning/locale/tr_TR/tutorials/10_effective_dimension.html">Turkish</a></dd>
      
        <dd><a class="version" href="/documentation/machine-learning/locale/vi_VN/tutorials/10_effective_dimension.html">Vietnamese</a></dd>
      
    </dl>
    
  </div>
  <script>
    jQuery('.version').click((evt) => {
      const hash = window.location.hash
      const complete_url = evt.target.href + hash
      window.location = complete_url
      evt.preventDefault()
    })
  </script>
</div>

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  0.4.0
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html">Premiers Pas</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Didacticiel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apidocs/qiskit_machine_learning.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../release_notes.html">Notes de mise à jour</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/Qiskit/qiskit-machine-learning">GitHub</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="index.html">Didacticiels Machine Learning</a> &gt;</li>
        
      <li>Effective Dimension of Qiskit Neural Networks</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/tutorials/10_effective_dimension.ipynb.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This page was generated from <a class="reference external" href="https://github.com/Qiskit/qiskit-machine-learning/blob/stable/0.4/docs/tutorials/10_effective_dimension.ipynb">docs/tutorials/10_effective_dimension.ipynb</a>.</p>
</div>
<section id="Effective-Dimension-of-Qiskit-Neural-Networks">
<h1>Effective Dimension of Qiskit Neural Networks<a class="headerlink" href="#Effective-Dimension-of-Qiskit-Neural-Networks" title="Lien permanent vers cette rubrique">¶</a></h1>
<p>In this tutorial, we will take advantage of the <code class="docutils literal notranslate"><span class="pre">EffectiveDimension</span></code> and <code class="docutils literal notranslate"><span class="pre">LocalEffectiveDimension</span></code> classes to evaluate the power of Quantum Neural Network models. These are metrics based on information geometry that connect to notions such as trainability, expressibility or ability to generalize.</p>
<p>Before diving into the code example, we will briefly explain what is the difference between these two metrics, and why are they relevant to the study of Quantum Neural Networks. More information about global effective dimension can be found in <a class="reference external" href="https://arxiv.org/pdf/2011.00027.pdf">this paper</a>, while the local effective dimension was introduced in a <a class="reference external" href="https://arxiv.org/abs/2112.04807">later work</a>.</p>
<section id="1.-Global-vs. Local-Effective-Dimension">
<h2>1. Global vs. Local Effective Dimension<a class="headerlink" href="#1.-Global-vs. Local-Effective-Dimension" title="Lien permanent vers cette rubrique">¶</a></h2>
<p>Both classical and quantum machine learning models share a common goal: being good at <strong>generalizing</strong>, i.e. learning insights from data and applying them on unseen data.</p>
<p>Finding a good metric to assess this ability is a non-trivial matter. In <a class="reference external" href="https://arxiv.org/pdf/2011.00027.pdf">The Power of Quantum Neural Networks</a>, the authors introduce the <strong>global</strong> effective dimension as a useful indicator of how well a particular model will be able to perform on new data. In <a class="reference external" href="https://arxiv.org/pdf/2112.04807.pdf">Effective Dimension of Machine Learning Models</a>, the <strong>local</strong> effective dimension is proposed as a new capacity measure that bounds the generalization
error of machine learning models.</p>
<p>The key difference between global (<code class="docutils literal notranslate"><span class="pre">EffectiveDimension</span></code> class) and <strong>local</strong> effective dimension (<code class="docutils literal notranslate"><span class="pre">LocalEffectiveDimension</span></code> class) is actually not in the way they are computed, but in the nature of the parameter space that is analyzed. The global effective dimension incorporates the <strong>full parameter space</strong> of the model, and is calculated from a <strong>large number of parameter (weight) sets</strong>. On the other hand, the local effective dimension focuses on how well the <strong>trained</strong> model can
generalize to new data, and how <strong>expressive</strong> it can be. Therefore, the local effective dimension is calculated from <strong>a single</strong> set of weight samples (training result). This difference is small in terms of practical implementation, but quite relevant at a conceptual level.</p>
</section>
<section id="2.-The-Effective-Dimension-Algorithm">
<h2>2. The Effective Dimension Algorithm<a class="headerlink" href="#2.-The-Effective-Dimension-Algorithm" title="Lien permanent vers cette rubrique">¶</a></h2>
<p>Both the global and local effective dimension algorithms use the Fisher Information matrix to provide a measure of complexity. The details on how this matrix is calculated are provided in the <a class="reference external" href="https://arxiv.org/pdf/2011.00027.pdf">reference paper</a>, but in general terms, this matrix captures how sensitive a neural network’s output is to changes in the network’s parameter space.</p>
<p>In particular, this algorithm follows 4 main steps:</p>
<ol class="arabic simple">
<li><p><strong>Monte Carlo simulation:</strong> the forward and backward passes (gradients) of the neural network are computed for each pair of input and weight samples.</p></li>
<li><p><strong>Fisher Matrix Computation:</strong> these outputs and gradients are used to compute the Fisher Information Matrix.</p></li>
<li><p><strong>Fisher Matrix Normalization:</strong> averaging over all input samples and dividing by the matrix trace</p></li>
<li><p><strong>Effective Dimension Calculation:</strong> according to the formula from <a class="reference external" href="https://arxiv.org/pdf/2011.00027.pdf">Abbas et al.</a></p></li>
</ol>
</section>
<section id="3.-Basic-Example-(CircuitQNN)">
<h2>3. Basic Example (CircuitQNN)<a class="headerlink" href="#3.-Basic-Example-(CircuitQNN)" title="Lien permanent vers cette rubrique">¶</a></h2>
<p>This example shows how to set up a QNN model problem and run the global effective dimension algorithm. Both Qiskit <code class="docutils literal notranslate"><span class="pre">CircuitQNN</span></code> (shown in this example) and <code class="docutils literal notranslate"><span class="pre">OpflowQNN</span></code> (shown in a later example) can be used with the <code class="docutils literal notranslate"><span class="pre">EffectiveDimension</span></code> class.</p>
<p>We start off from the required imports and a fixed seed for the random number generator for reproducibility purposes.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Necessary imports</span>
<span class="kn">from</span> <span class="nn">qiskit.circuit.library</span> <span class="kn">import</span> <span class="n">ZFeatureMap</span><span class="p">,</span> <span class="n">ZZFeatureMap</span><span class="p">,</span> <span class="n">RealAmplitudes</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">qiskit_machine_learning.neural_networks</span> <span class="kn">import</span> <span class="n">CircuitQNN</span><span class="p">,</span> <span class="n">TwoLayerQNN</span>
<span class="kn">from</span> <span class="nn">qiskit.utils</span> <span class="kn">import</span> <span class="n">QuantumInstance</span><span class="p">,</span> <span class="n">algorithm_globals</span>
<span class="kn">from</span> <span class="nn">qiskit</span> <span class="kn">import</span> <span class="n">Aer</span><span class="p">,</span> <span class="n">QuantumCircuit</span>

<span class="kn">from</span> <span class="nn">qiskit_machine_learning.neural_networks</span> <span class="kn">import</span> <span class="n">EffectiveDimension</span><span class="p">,</span> <span class="n">LocalEffectiveDimension</span>

<span class="kn">from</span> <span class="nn">qiskit_machine_learning.algorithms.classifiers</span> <span class="kn">import</span> <span class="n">NeuralNetworkClassifier</span><span class="p">,</span> <span class="n">VQC</span>
<span class="kn">from</span> <span class="nn">qiskit.algorithms.optimizers</span> <span class="kn">import</span> <span class="n">COBYLA</span>

<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">clear_output</span>

<span class="c1"># set random seed</span>
<span class="n">algorithm_globals</span><span class="o">.</span><span class="n">random_seed</span> <span class="o">=</span> <span class="mi">42</span>
</pre></div>
</div>
</div>
<section id="3.1-Define-QNN">
<h3>3.1 Define QNN<a class="headerlink" href="#3.1-Define-QNN" title="Lien permanent vers cette rubrique">¶</a></h3>
<p>The first step to create a <code class="docutils literal notranslate"><span class="pre">CircuitQNN</span></code> is to define a parametrized feature map and ansatz. In this toy example, we will use 3 qubits, and we will define the circuit used in the <code class="docutils literal notranslate"><span class="pre">TwoLayerQNN</span></code> class.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_qubits</span> <span class="o">=</span> <span class="mi">3</span>
<span class="c1"># create a feature map</span>
<span class="n">feature_map</span> <span class="o">=</span> <span class="n">ZFeatureMap</span><span class="p">(</span><span class="n">feature_dimension</span><span class="o">=</span><span class="n">num_qubits</span><span class="p">,</span> <span class="n">reps</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># create a variational circuit</span>
<span class="n">ansatz</span> <span class="o">=</span> <span class="n">RealAmplitudes</span><span class="p">(</span><span class="n">num_qubits</span><span class="p">,</span> <span class="n">reps</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># combine feature map and ansatz into a single circuit</span>
<span class="n">qc</span> <span class="o">=</span> <span class="n">QuantumCircuit</span><span class="p">(</span><span class="n">num_qubits</span><span class="p">)</span>
<span class="n">qc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">feature_map</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_qubits</span><span class="p">))</span>
<span class="n">qc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ansatz</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_qubits</span><span class="p">))</span>
<span class="n">qc</span><span class="o">.</span><span class="n">decompose</span><span class="p">()</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="s2">&quot;mpl&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_10_effective_dimension_6_0.png" src="../_images/tutorials_10_effective_dimension_6_0.png" />
</div>
</div>
<p>The parametrized circuit can then be sent together with an optional interpret map (parity in this case) to the <code class="docutils literal notranslate"><span class="pre">CircuitQNN</span></code> constructor.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># parity maps bitstrings to 0 or 1</span>
<span class="k">def</span> <span class="nf">parity</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{:b}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s2">&quot;1&quot;</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span>


<span class="n">output_shape</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># corresponds to the number of classes, possible outcomes of the (parity) mapping.</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># declare quantum instance</span>
<span class="n">qi_sv</span> <span class="o">=</span> <span class="n">QuantumInstance</span><span class="p">(</span><span class="n">Aer</span><span class="o">.</span><span class="n">get_backend</span><span class="p">(</span><span class="s2">&quot;aer_simulator_statevector&quot;</span><span class="p">))</span>

<span class="c1"># construct QNN</span>
<span class="n">qnn</span> <span class="o">=</span> <span class="n">CircuitQNN</span><span class="p">(</span>
    <span class="n">qc</span><span class="p">,</span>
    <span class="n">input_params</span><span class="o">=</span><span class="n">feature_map</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span>
    <span class="n">weight_params</span><span class="o">=</span><span class="n">ansatz</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span>
    <span class="n">interpret</span><span class="o">=</span><span class="n">parity</span><span class="p">,</span>
    <span class="n">output_shape</span><span class="o">=</span><span class="n">output_shape</span><span class="p">,</span>
    <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">quantum_instance</span><span class="o">=</span><span class="n">qi_sv</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="3.2-Set-up-Effective-Dimension-calculation">
<h3>3.2 Set up Effective Dimension calculation<a class="headerlink" href="#3.2-Set-up-Effective-Dimension-calculation" title="Lien permanent vers cette rubrique">¶</a></h3>
<p>In order to compute the effective dimension of our QNN using the <code class="docutils literal notranslate"><span class="pre">EffectiveDimension</span></code> class, we need a series of sets of input samples and weights, as well as the total number of data samples available in a dataset. The <code class="docutils literal notranslate"><span class="pre">input_samples</span></code> and <code class="docutils literal notranslate"><span class="pre">weight_samples</span></code> are set in the class constructor, while the number of data samples is given during the call to the effective dimension computation, to be able to test and compare how this measure changes with different dataset sizes.</p>
<p>We can define the number of input samples and weight samples and the class will randomly sample a corresponding array from a normal (for <code class="docutils literal notranslate"><span class="pre">input_samples</span></code>) or a uniform (for <code class="docutils literal notranslate"><span class="pre">weight_samples</span></code>) distribution. Instead of passing a number of samples we can pass an array, sampled manually.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># we can set the total number of input samples and weight samples for random selection</span>
<span class="n">num_input_samples</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">num_weight_samples</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">global_ed</span> <span class="o">=</span> <span class="n">EffectiveDimension</span><span class="p">(</span>
    <span class="n">qnn</span><span class="o">=</span><span class="n">qnn</span><span class="p">,</span> <span class="n">weight_samples</span><span class="o">=</span><span class="n">num_weight_samples</span><span class="p">,</span> <span class="n">input_samples</span><span class="o">=</span><span class="n">num_input_samples</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>If we want to test a specific set of input samples and weight samples, we can provide it directly to the <code class="docutils literal notranslate"><span class="pre">EffectiveDimension</span></code> class as shown in the following snippet:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># we can also provide user-defined samples and parameters</span>
<span class="n">input_samples</span> <span class="o">=</span> <span class="n">algorithm_globals</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">qnn</span><span class="o">.</span><span class="n">num_inputs</span><span class="p">))</span>
<span class="n">weight_samples</span> <span class="o">=</span> <span class="n">algorithm_globals</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">qnn</span><span class="o">.</span><span class="n">num_weights</span><span class="p">))</span>

<span class="n">global_ed</span> <span class="o">=</span> <span class="n">EffectiveDimension</span><span class="p">(</span><span class="n">qnn</span><span class="o">=</span><span class="n">qnn</span><span class="p">,</span> <span class="n">weight_samples</span><span class="o">=</span><span class="n">weight_samples</span><span class="p">,</span> <span class="n">input_samples</span><span class="o">=</span><span class="n">input_samples</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The effective dimension algorithm also requires a dataset size. In this example, we will define an array of sizes to later see how this input affects the result.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># finally, we will define ranges to test different numbers of data, n</span>
<span class="n">n</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">8000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="mi">40000</span><span class="p">,</span> <span class="mi">60000</span><span class="p">,</span> <span class="mi">100000</span><span class="p">,</span> <span class="mi">150000</span><span class="p">,</span> <span class="mi">200000</span><span class="p">,</span> <span class="mi">500000</span><span class="p">,</span> <span class="mi">1000000</span><span class="p">]</span>
</pre></div>
</div>
</div>
</section>
<section id="3.3-Compute-Global-Effective-Dimension">
<h3>3.3 Compute Global Effective Dimension<a class="headerlink" href="#3.3-Compute-Global-Effective-Dimension" title="Lien permanent vers cette rubrique">¶</a></h3>
<p>Let’s now calculate the effective dimension of our network for the previously defined set of input samples, weights, and a dataset size of 5000.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">global_eff_dim_0</span> <span class="o">=</span> <span class="n">global_ed</span><span class="o">.</span><span class="n">get_effective_dimension</span><span class="p">(</span><span class="n">dataset_size</span><span class="o">=</span><span class="n">n</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<p>The effective dimension values will range between 0 and <code class="docutils literal notranslate"><span class="pre">d</span></code>, where <code class="docutils literal notranslate"><span class="pre">d</span></code> represents the dimension of the model, and it’s practically obtained from the number of weights of the QNN. By dividing the result by <code class="docutils literal notranslate"><span class="pre">d</span></code>, we can obtain the normalized effective dimension, which correlates directly with the capacity of the model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">d</span> <span class="o">=</span> <span class="n">qnn</span><span class="o">.</span><span class="n">num_weights</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data size: </span><span class="si">{}</span><span class="s2">, global effective dimension: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">global_eff_dim_0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Number of weights: </span><span class="si">{}</span><span class="s2">, normalized effective dimension: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">global_eff_dim_0</span> <span class="o">/</span> <span class="n">d</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Data size: 5000, global effective dimension: 4.6657
Number of weights: 6, normalized effective dimension: 0.7776
</pre></div></div>
</div>
<p>By calling the <code class="docutils literal notranslate"><span class="pre">EffectiveDimension</span></code> class with an array if input sizes <code class="docutils literal notranslate"><span class="pre">n</span></code>, we can monitor how the effective dimension changes with the dataset size.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">global_eff_dim_1</span> <span class="o">=</span> <span class="n">global_ed</span><span class="o">.</span><span class="n">get_effective_dimension</span><span class="p">(</span><span class="n">dataset_size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Effective dimension: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">global_eff_dim_1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of weights: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">d</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Effective dimension: [4.66565096 4.7133723  4.73782922 4.89963559 4.94632272 5.00280009
 5.04530433 5.07408394 5.15786005 5.21349874]
Number of weights: 6
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot the normalized effective dimension for the model</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">global_eff_dim_1</span><span class="p">)</span> <span class="o">/</span> <span class="n">d</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Number of data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Normalized GLOBAL effective dimension&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_10_effective_dimension_24_0.png" src="../_images/tutorials_10_effective_dimension_24_0.png" />
</div>
</div>
</section>
</section>
<section id="4.-Local-Effective-Dimension-Example">
<h2>4. Local Effective Dimension Example<a class="headerlink" href="#4.-Local-Effective-Dimension-Example" title="Lien permanent vers cette rubrique">¶</a></h2>
<p>As explained in the introduction, the local effective dimension algorithm only uses <strong>one</strong> set of weights, and it can be used to monitor how training affects the expressiveness of a neural network. The <code class="docutils literal notranslate"><span class="pre">LocalEffectiveDimension</span></code> class enforces this constraint to ensure that these calculations are conceptually separate, but the rest of the implementation is shared with <code class="docutils literal notranslate"><span class="pre">EffectiveDimension</span></code>.</p>
<p>This example shows how to leverage the <code class="docutils literal notranslate"><span class="pre">LocalEffectiveDimension</span></code> class to analyze the effect of training on QNN expressiveness.</p>
<section id="4.1-Define-Dataset-and-QNN">
<h3>4.1 Define Dataset and QNN<a class="headerlink" href="#4.1-Define-Dataset-and-QNN" title="Lien permanent vers cette rubrique">¶</a></h3>
<p>We start by creating a 3D binary classification dataset:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_inputs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">algorithm_globals</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">))</span>

<span class="n">y01</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># in { 0,  1}</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">y01</span> <span class="o">-</span> <span class="mi">1</span>  <span class="c1"># in {-1, +1}</span>
</pre></div>
</div>
</div>
<p>The next step is to create a QNN, an instance of <code class="docutils literal notranslate"><span class="pre">TwoLayerQNN</span></code> in our case. Since we pass only the number of inputs, the network will continue with the default values for feature map and ansatz.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">opflow_qnn</span> <span class="o">=</span> <span class="n">TwoLayerQNN</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">quantum_instance</span><span class="o">=</span><span class="n">qi_sv</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="4.2-Train-QNN">
<h3>4.2 Train QNN<a class="headerlink" href="#4.2-Train-QNN" title="Lien permanent vers cette rubrique">¶</a></h3>
<p>We can now proceed to train the QNN. The training step may take some time, be patient. You can pass a callback to the classifier to observe how the training process is going on. We fix <code class="docutils literal notranslate"><span class="pre">initial_point</span></code> for reproducibility purposes as usual.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># callback function that draws a live plot when the .fit() method is called</span>
<span class="k">def</span> <span class="nf">callback_graph</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">obj_func_eval</span><span class="p">):</span>
    <span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">objective_func_vals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">obj_func_eval</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Objective function value against iteration&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Iteration&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Objective function value&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">objective_func_vals</span><span class="p">)),</span> <span class="n">objective_func_vals</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># construct classifier</span>
<span class="n">initial_point</span> <span class="o">=</span> <span class="n">algorithm_globals</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">opflow_qnn</span><span class="o">.</span><span class="n">num_weights</span><span class="p">)</span>

<span class="n">opflow_classifier</span> <span class="o">=</span> <span class="n">NeuralNetworkClassifier</span><span class="p">(</span>
    <span class="n">neural_network</span><span class="o">=</span><span class="n">opflow_qnn</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">COBYLA</span><span class="p">(</span><span class="n">maxiter</span><span class="o">=</span><span class="mi">150</span><span class="p">),</span>
    <span class="n">initial_point</span><span class="o">=</span><span class="n">initial_point</span><span class="p">,</span>
    <span class="n">callback</span><span class="o">=</span><span class="n">callback_graph</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create empty array for callback to store evaluations of the objective function (callback)</span>
<span class="n">objective_func_vals</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;figure.figsize&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>

<span class="c1"># fit classifier to data</span>
<span class="n">opflow_classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># return to default figsize</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;figure.figsize&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_10_effective_dimension_33_0.png" src="../_images/tutorials_10_effective_dimension_33_0.png" />
</div>
</div>
<p>The classifier can now differentiate between classes with an accuracy of:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># score classifier</span>
<span class="n">opflow_classifier</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.68
</pre></div></div>
</div>
</section>
<section id="4.3-Compute-Local-Effective-Dimension-of-trained-QNN">
<h3>4.3 Compute Local Effective Dimension of trained QNN<a class="headerlink" href="#4.3-Compute-Local-Effective-Dimension-of-trained-QNN" title="Lien permanent vers cette rubrique">¶</a></h3>
<p>Now that we have trained our network, let’s evaluate the local effective dimension based on the trained weights. To do that we access the trained weights directly from the classifier.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trained_weights</span> <span class="o">=</span> <span class="n">opflow_classifier</span><span class="o">.</span><span class="n">_fit_result</span><span class="o">.</span><span class="n">x</span>

<span class="c1"># get Local Effective Dimension for set of trained weights</span>
<span class="n">local_ed_trained</span> <span class="o">=</span> <span class="n">LocalEffectiveDimension</span><span class="p">(</span>
    <span class="n">qnn</span><span class="o">=</span><span class="n">opflow_qnn</span><span class="p">,</span> <span class="n">weight_samples</span><span class="o">=</span><span class="n">trained_weights</span><span class="p">,</span> <span class="n">input_samples</span><span class="o">=</span><span class="n">X</span>
<span class="p">)</span>

<span class="n">local_eff_dim_trained</span> <span class="o">=</span> <span class="n">local_ed_trained</span><span class="o">.</span><span class="n">get_effective_dimension</span><span class="p">(</span><span class="n">dataset_size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;normalized local effective dimensions for trained QNN: &quot;</span><span class="p">,</span>
    <span class="n">local_eff_dim_trained</span> <span class="o">/</span> <span class="n">opflow_qnn</span><span class="o">.</span><span class="n">num_weights</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
normalized local effective dimensions for trained QNN:  [0.79663244 0.80325759 0.80653351 0.82723511 0.83320702 0.84062917
 0.84641928 0.85045673 0.86276589 0.87134912]
</pre></div></div>
</div>
</section>
<section id="4.4-Compute-Local-Effective-Dimension-of-untrained-QNN">
<h3>4.4 Compute Local Effective Dimension of untrained QNN<a class="headerlink" href="#4.4-Compute-Local-Effective-Dimension-of-untrained-QNN" title="Lien permanent vers cette rubrique">¶</a></h3>
<p>We can compare this result with the effective dimension of the untrained network, using the <code class="docutils literal notranslate"><span class="pre">initial_point</span></code> as our weight sample:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># get Local Effective Dimension for set of untrained weights</span>
<span class="n">local_ed_untrained</span> <span class="o">=</span> <span class="n">LocalEffectiveDimension</span><span class="p">(</span>
    <span class="n">qnn</span><span class="o">=</span><span class="n">opflow_qnn</span><span class="p">,</span> <span class="n">weight_samples</span><span class="o">=</span><span class="n">initial_point</span><span class="p">,</span> <span class="n">input_samples</span><span class="o">=</span><span class="n">X</span>
<span class="p">)</span>

<span class="n">local_eff_dim_untrained</span> <span class="o">=</span> <span class="n">local_ed_untrained</span><span class="o">.</span><span class="n">get_effective_dimension</span><span class="p">(</span><span class="n">dataset_size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;normalized local effective dimensions for untrained QNN: &quot;</span><span class="p">,</span>
    <span class="n">local_eff_dim_untrained</span> <span class="o">/</span> <span class="n">opflow_qnn</span><span class="o">.</span><span class="n">num_weights</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
normalized local effective dimensions for untrained QNN:  [0.80896667 0.81612261 0.81966781 0.84219603 0.84864578 0.85651291
 0.86249025 0.86656428 0.8785217  0.88651616]
</pre></div></div>
</div>
</section>
<section id="4.5-Plot-and-analyze-results">
<h3>4.5 Plot and analyze results<a class="headerlink" href="#4.5-Plot-and-analyze-results" title="Lien permanent vers cette rubrique">¶</a></h3>
<p>If we plot the effective dimension values before and after training, we can see the following result:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot the normalized effective dimension for the model</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">local_eff_dim_trained</span><span class="p">)</span> <span class="o">/</span> <span class="n">opflow_qnn</span><span class="o">.</span><span class="n">num_weights</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;trained weights&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">local_eff_dim_untrained</span><span class="p">)</span> <span class="o">/</span> <span class="n">opflow_qnn</span><span class="o">.</span><span class="n">num_weights</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;untrained weights&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Number of data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Normalized LOCAL effective dimension&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_10_effective_dimension_41_0.png" src="../_images/tutorials_10_effective_dimension_41_0.png" />
</div>
</div>
<p>In general, we should expect the value of the local effective dimension to decrease after training. This can be understood by looking back into the main goal of machine learning, which is to pick a model that is expressive enough to fit your data, but not too expressive that it overfits and performs badly on new data samples.</p>
<p>Certain optimizers help regularize the overfitting of a model by learning parameters, and this action of learning inherently reduces a model’s expressiveness, as measured by the local effective dimension. Following this logic, a randomly initialized parameter set will most likely produce a higher effective dimension that the final set of trained weights, because that model with that particular parameterization is “using more parameters” unnecessarily to fit the data. After training (with the
implicit regularization), a trained model will not need to use so many parameters and thus have more “inactive parameters” and a lower effective dimension.</p>
<p>We must keep in mind though that this is the general intuition, and there might be cases where a randomly selected set of weights happens to provide a lower effective dimension than the trained weights for a specific model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">qiskit.tools.jupyter</span>

<span class="o">%</span><span class="k">qiskit_version_table</span>
<span class="o">%</span><span class="k">qiskit_copyright</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<h3>Version Information</h3><table><tr><th>Qiskit Software</th><th>Version</th></tr><tr><td><code>qiskit-terra</code></td><td>0.20.1</td></tr><tr><td><code>qiskit-aer</code></td><td>0.10.3</td></tr><tr><td><code>qiskit-ignis</code></td><td>0.7.0</td></tr><tr><td><code>qiskit-ibmq-provider</code></td><td>0.18.3</td></tr><tr><td><code>qiskit</code></td><td>0.34.2</td></tr><tr><td><code>qiskit-machine-learning</code></td><td>0.4.0</td></tr><tr><th>System information</th></tr><tr><td>Python version</td><td>3.10.0</td></tr><tr><td>Python compiler</td><td>Clang 12.0.0 </td></tr><tr><td>Python build</td><td>default, Nov 10 2021 11:24:47</td></tr><tr><td>OS</td><td>Darwin</td></tr><tr><td>CPUs</td><td>8</td></tr><tr><td>Memory (Gb)</td><td>64.0</td></tr><tr><td colspan='2'>Tue Apr 26 21:08:28 2022 CEST</td></tr></table></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<div style='width: 100%; background-color:#d5d9e0;padding-left: 10px; padding-bottom: 10px; padding-right: 10px; padding-top: 5px'><h3>This code is a part of Qiskit</h3><p>&copy; Copyright IBM 2017, 2022.</p><p>This code is licensed under the Apache License, Version 2.0. You may<br>obtain a copy of this license in the LICENSE.txt file in the root directory<br> of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.<p>Any modifications or derivative works of this code must retain this<br>copyright notice, and modified files need to carry a notice indicating<br>that they have been altered from the originals.</p></div></div>
</div>
</section>
</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../apidocs/qiskit_machine_learning.html" class="btn btn-neutral float-right" title="Qiskit Machine Learning API Reference" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="09_saving_and_loading%20models.html" class="btn btn-neutral" title="Saving, Loading Qiskit Machine Learning Models and Continuous Training" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, 2021, Qiskit Machine Learning Development Team.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Effective Dimension of Qiskit Neural Networks</a><ul>
<li><a class="reference internal" href="#1.-Global-vs. Local-Effective-Dimension">1. Global vs. Local Effective Dimension</a></li>
<li><a class="reference internal" href="#2.-The-Effective-Dimension-Algorithm">2. The Effective Dimension Algorithm</a></li>
<li><a class="reference internal" href="#3.-Basic-Example-(CircuitQNN)">3. Basic Example (CircuitQNN)</a><ul>
<li><a class="reference internal" href="#3.1-Define-QNN">3.1 Define QNN</a></li>
<li><a class="reference internal" href="#3.2-Set-up-Effective-Dimension-calculation">3.2 Set up Effective Dimension calculation</a></li>
<li><a class="reference internal" href="#3.3-Compute-Global-Effective-Dimension">3.3 Compute Global Effective Dimension</a></li>
</ul>
</li>
<li><a class="reference internal" href="#4.-Local-Effective-Dimension-Example">4. Local Effective Dimension Example</a><ul>
<li><a class="reference internal" href="#4.1-Define-Dataset-and-QNN">4.1 Define Dataset and QNN</a></li>
<li><a class="reference internal" href="#4.2-Train-QNN">4.2 Train QNN</a></li>
<li><a class="reference internal" href="#4.3-Compute-Local-Effective-Dimension-of-trained-QNN">4.3 Compute Local Effective Dimension of trained QNN</a></li>
<li><a class="reference internal" href="#4.4-Compute-Local-Effective-Dimension-of-untrained-QNN">4.4 Compute Local Effective Dimension of untrained QNN</a></li>
<li><a class="reference internal" href="#4.5-Plot-and-analyze-results">4.5 Plot and analyze results</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="../_static/thebelab-helper.js"></script>
         <script src="../_static/translations.js"></script>
         <script src="../_static/design-tabs.js"></script>
         <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
         <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
         <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
         <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
         <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


  <div>
    <br>
  </div>

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://qiskit.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="../getting_started.html">Getting Started</a>
          </li>
          <li>
            <a href="https://qiskit.org/documentation/machine-learning/tutorials/index.html" target="_blank">Tutorials</a>
          </li>
          <li>
            <a href="https://qiskit.org/documentation/partners/">Partners</a>
          </li>
          <br>
          <li class="resources-mobile-menu-title">
            Applications
          </li>
          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://qiskit.org/documentation/machine-learning/">Machine learning</a>
            </li>

            <li>
              <a href="https://qiskit.org/documentation/nature/">Nature</a>
            </li>

            <li>
              <a href="https://qiskit.org/documentation/finance/">Finance</a>
            </li>

            <li>
              <a href="https://qiskit.org/documentation/optimization/">Optimization</a>
            </li>
          </ul>
          <br>
          <li>
            <a href="https://qiskit.org/documentation/experiments/">Experiments</a>
          </li>
          <br>
          <li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://qiskit.slack.com">Slack support</a>
            </li>
          </ul>
          <br>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>